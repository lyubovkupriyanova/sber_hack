{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Install cudf"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport sys\n!cp ../input/rapids/rapids.0.14.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from glob import glob\nimport pandas as pd\nimport cudf\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_files = glob('/kaggle/input/test-recsys/sbermarket_tab_2_*/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndfs = []\nfor path in all_files[:15]:\n    dfs.append(\n        # reduce_mem_usage(\n            cudf.read_csv(path, \n                          usecols=['user_id', 'order_id', 'line_item_id', 'price', 'quantity', 'discount',\n                                   'product_id', 'master_category_id', 'parent_category_id'])\n        # )\n    )\ntotal_df = cudf.concat(dfs, axis=0)\ndel dfs\n\ndfs = []\nfor path in all_files[15:]:\n    dfs.append(\n        # reduce_mem_usage(\n            cudf.read_csv(path, \n                          usecols=['user_id', 'order_id', 'line_item_id', 'price', 'quantity', 'discount',\n                                   'product_id', 'master_category_id', 'parent_category_id'])\n        # )\n    )\ndfs.append(total_df)\ntotal_df = cudf.concat(dfs, axis=0)\ndel dfs\n\n\nprint('Total df shape', total_df.shape)\n\norders_df = cudf.read_csv('/kaggle/input/test-recsys/kaggle_tab_1345/tab_1_orders.csv')\nprint('Orders shape', orders_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products_df = cudf.read_csv('/kaggle/input/test-recsys/kaggle_tab_1345/tab_5_product_properties.csv')\nprint('Orders shape', products_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = cudf.read_csv('/kaggle/input/test-recsys/sample_submission.csv')\nprint('Submission shape', submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_count = 10_000\n\nfull_len = len(total_df)\nproduct_id_vc = total_df.product_id.value_counts()\ntop_items_by_count = product_id_vc[product_id_vc > min_count].index\n\n\ntotal_df = total_df[total_df['product_id'].isin(top_items_by_count)]\nprint(\n    (min_count / full_len) * 100\n)\nprint(total_df.shape)\ntotal_df.product_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_df_orders = total_df.order_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove users with only one order"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEBUG_USERS_SIZE = 10_000 * 50\n# def filter_user_with_one_order(df, orders_in_total_df):\n#     df = df[\n#         df.order_id.isin(orders_in_total_df)\n#     ]\n#     orders_group_by_user_id = df.groupby('user_id')\n#     orders_count_by_users = orders_group_by_user_id['order_id'].count()\n#     users_with_more_than_one_order = orders_count_by_users[\n#         (orders_count_by_users != 1)\n#     ].index\n#     # users_with_more_than_one_order = np.random.choice(users_with_more_than_one_order.to_array(), DEBUG_USERS_SIZE)\n#     return df[df['user_id'].isin(users_with_more_than_one_order)]\n# users_with_more_than_one_order = filter_user_with_one_order(orders_df, total_df_orders)\n\n# users_with_more_than_one_order_pd = users_with_more_than_one_order.to_pandas()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make dataframe with feature order ids and target ored id"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset = pd.read_csv('/kaggle/input/sbermarketdata/dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# def get_featurs_target_apply(df):\n#     time = df['order_created_time'].sort_values().index\n    \n#     target_idx = time[-1]\n#     target = df.loc[target_idx]\n    \n#     features_idx = time[:-1]\n#     features = df.loc[features_idx]\n#     return (features.order_id.values, target.order_id)\n\n# dataset = users_with_more_than_one_order_pd.groupby('user_id').apply(get_featurs_target_apply).reset_index()\n# dataset = dataset.set_index('user_id')\n# dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_df = pd.read_pickle('/kaggle/input/sbermarketdata/orders')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = res_df['features']\ntarget = res_df['target_idx']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# res_df['user_id'] = dataset.index\n# res_df['features'] = features\n# res_df['target_idx'] = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n\n# with open('orders', 'rb') as f:\n#     res_df_read = pickle.load(f)\n    \n# with open('orders', 'wb') as f:\n#     pickle.dump(res_df, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From feature orders aggregate and extract information"},{"metadata":{"trusted":true},"cell_type":"code","source":"def price_agg(price):\n    return (price.mean(), price.std(), price.median())\n\ndef pad_if_need(a, l):\n    if len(a) != l:\n        a = np.pad(a, (0, l - len(a)))\n        return a\n    \n    return a\n    \n\ndef quantity_agg(quantity):\n    return (quantity.mean(), quantity.std(), quantity.median())\n\ndef extract_features(df,topk=25):\n    top_parent_category = df.parent_category_id.value_counts()[:topk].index.to_array()\n    top_parent_category = pad_if_need(top_parent_category, topk)\n    \n    top_product_id = df.product_id.value_counts()[:topk].index.to_array()    \n    top_product_id = pad_if_need(top_product_id, topk)\n        \n    price_agg_res = price_agg(df.price)\n    quantity_agg_res = quantity_agg(df.quantity)\n    \n    return np.concatenate((\n        top_parent_category,\n        top_product_id,\n        price_agg_res,\n        quantity_agg_res\n    )).astype('float32')\n\n\ndef get_target_vector(order):\n    return order.product_id.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features = [i[0] for i in dataset.iloc[:,-1]]\n\n\nfeatures = res_df['features']\nfeatures = np.concatenate(features)\n\ntarget = res_df['target_idx']\n\n# target = [i[1] for i in dataset.iloc[:,-1]]\n\n\nuser_id = res_df.user_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEBUG_SIZE = 100_000 * 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_total_df = total_df[total_df.order_id.isin(features[:DEBUG_SIZE])].to_pandas()\nfeatures_total_df_gb_user_id = features_total_df.groupby('user_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_ids = features_total_df_gb_user_id.groups.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_total_df = total_df[total_df.order_id.isin(target) & total_df.user_id.isin(user_ids)].to_pandas()\ntarget_total_df_gb_user_id = target_total_df.groupby('user_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_target_apply(df):\n    return df.product_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ny = target_total_df_gb_user_id.apply(get_target_apply)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_product_list = features_total_df_gb_user_id.apply(get_target_apply)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(features_product_list, columns = ['lists']).to_parquet('features_product_list.parquet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features_total_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tmp = features_total_df.drop(['order_id','line_item_id',\n#                               'price','quantity',\n#                               'discount','master_category_id',\n#                               'parent_category_id'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tmp = tmp.drop_duplicates()\n# import pickle\n# with open('feat_prod.parquet','wb') as f:\n#     tmp.to_parquet(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tmp = tmp.drop_duplicates()\n# tmp = pd.get_dummies(tmp,columns = ['product_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n# with open('feat_prod.pkl','wb') as f:\n#     pickle.dump(tmp,f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features_product = tmp.groupby('user_id').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features_submission(df,topk=7):\n    top_parent_category = df.parent_category_id.value_counts()[:topk].index\n    top_parent_category = pad_if_need(top_parent_category, topk)\n    \n    top_product_id = df.product_id.value_counts()[:topk].index\n    top_product_id = pad_if_need(top_product_id, topk)\n        \n    price_agg_res = price_agg(df.price)\n    quantity_agg_res = quantity_agg(df.quantity)\n    \n    return np.concatenate((\n        top_parent_category,\n        top_product_id,\n        price_agg_res,\n        quantity_agg_res\n    )).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX = features_total_df_gb_user_id.apply(extract_features_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = X.reset_index().merge(y.reset_index(), left_on='user_id', right_on='user_id')\nmatrix = matrix.rename(columns={\"0_x\": \"features\", \"0_y\": \"target_ids\"})\n# matrix.to_csv('dataset', index='user_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# matrix['features'][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n# with open('dataset_v3', 'wb') as f:\n#     pickle.dump(matrix, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n# with open('dataset_v3', 'rb') as f:\n#     matrix = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix['features'].values.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# with open('dataset_v2', 'wb') as f:\n#     pickle.dump(matrix, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#matrix = matrix.iloc[:10_000]\nuniq_target = np.unique(\n    np.hstack(matrix['target_ids'].values)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uniq_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open('uniq_target.pkl', 'wb') as f:\n    pickle.dump(uniq_target,f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def concat_users_features_item_features(feats, target, all_targets):\n#     x = []\n#     y = []\n#     for cur_target in all_targets:          \n#         _x = np.hstack((\n#             feats, cur_target\n#         ))\n        \n        \n#         assert _x.shape[0] == 13\n#         _y = cur_target in target\n        \n        \n#         x.append(_x)\n#         y.append(_y)\n        \n#     return x, np.array(y).astype('int32')\n\n# x,y = concat_users_features_item_features(matrix.features[0], matrix.target_ids[0], uniq_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.vstack(matrix.features.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Product features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_product_features(df):\n    tmp = df.copy()\n    tmp = tmp.drop(['user_id','order_id', 'line_item_id'],\n                   axis = 1)\n    tmp = tmp.groupby('product_id').agg(['mean','std','median'])\n    tmp.columns = [a+'_'+b for a,b in tmp.columns]\n    tmp = tmp.drop(['master_category_id_std','master_category_id_median',\n                      'parent_category_id_std','parent_category_id_median'],\n            axis = 1)\n    tmp.columns = list(tmp.columns[:-2]) +['parent_category', 'master_category']\n    tmp.reset_index(inplace = True)\n    return tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"product_features = get_product_features(features_total_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"product_features = product_features[product_features.product_id.isin(uniq_target)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"product_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n# with open('prod.pkl', 'wb') as f:\n#     pickle.dump(product_features, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Co-Product features"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_product","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = np.concatenate(np.array(features_product))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del total_df\ndel orders_df\ndel total_df_orders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\ndef get_cooccurence_features(features_product, uniq_target):\n    result = pd.DataFrame(features_product.copy()).reset_index()\n    result = pd.DataFrame(result.values.repeat(len(uniq_target), axis = 0), columns=result.columns)\n    tmp = uniq_target.copy()\n    tmp = pd.DataFrame(tmp[:None])\n    tmp = pd.DataFrame(np.concatenate([tmp.values]*len(features_product.index))[:None])\n    result = pd.concat([result, tmp], axis = 1)\n    del tmp\n    result.columns = ['user_id', 'products', 'cur_product']\n    result['nij'] = 0\n    result['nij/ni'] = 0\n    ni = {}\n    all_prods = np.concatenate(np.array(features_product))\n    for i in all_prods:\n        if i in ni:\n            ni[i]+=1\n        else:\n            ni[i] = 0\n    del all_prods\n    for i in tqdm(range(len(result.index))):\n        cur_prod = result.iloc[i,2]\n        nij = []\n        nij_div_nj = []\n        for j in result.iloc[i,1]:\n            if j == cur_prod:\n                continue\n            nij.append(0)\n            for k in range(features_product.shape[0]):\n                if cur_prod in features_product.iloc[k] and j in features_product.iloc[k]:\n                    nij[-1]+=1\n            nij_div_nj = nij[-1]/ni[j]\n        result.iloc[i,3] = np.mean(nij)\n        result.iloc[i,4] = np.mean(nij_div_nj)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_cooccurence_features(features_product, uniq_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n# with open('user_prod.pkl', 'wb') as f:\n#     pickle.dump(features_product, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_X = np.repeat(X, len(uniq_target), axis=0)\nwhole_y = np.repeat(np.zeros_like(uniq_target), len(X), axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"del X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nidxes = le.fit_transform(uniq_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, _cur in tqdm(enumerate(matrix.target_ids)):    \n    start_idx = idx * len(uniq_target)\n    end_idx = (idx + 1) * len(uniq_target)\n    whole_X[start_idx:end_idx] = matrix['features'].iloc[idx]\n    # whole_X[start_idx:end_idx][:,0] = matrix['user_id'].iloc[idx]\n    target_idxes = le.transform(_cur)\n    whole_y[start_idx:end_idx][target_idxes] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nidxes = le.fit_transform(uniq_target)\n\nfor idx, _cur in tqdm(enumerate(matrix.target_ids)):    \n    start_idx = idx * len(uniq_target)\n    end_idx = (idx + 1) * len(uniq_target)\n    whole_X[start_idx:end_idx] = matrix['features'].iloc[idx]\n    whole_X[start_idx:end_idx][:,-1] = np.arange(len(le.classes_))\n    whole_X[start_idx:end_idx][:,-2] = matrix['user_id'].iloc[idx]\n    target_idxes = le.transform(_cur)\n    whole_y[start_idx:end_idx][target_idxes] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"matrix['user_id'].iloc[idx]"},{"metadata":{"trusted":true},"cell_type":"code","source":"del orders_df\ndel total_df\n#del dataset\n#del users_with_more_than_one_order_pd\ndel products_df\ndel dfs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Co-occurence"},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = X[:392 * 400]\n# y_train = y[:392 * 400]\n\n# X_test = X[392 * 400:]\n# y_test = y[392 * 400:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# whole_y, whole_X\nX_train, X_test, y_train, y_test = train_test_split(whole_X, whole_y, \n                                                    test_size=0.33, \n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del whole_X\ndel whole_y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import catboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dataset = catboost.Pool(\n#     X_train, labels=y_train, weight=[0.1, 0.2, 0.3]\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_neg = len(y_train) - y_train.sum()\npos_sum = y_train.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost_params = {\n    'iterations':100, \n    # 'learning_rate':0.1, \n#                    'depth':10, \n#                    'l2_leaf_reg':10, \n    'random_state':7,\n    'eval_metric':'AUC',\n#                    'thread_count':10,  \n#                    'od_type': \"Iter\",'od_wait':10\n                  }\n\ncbc = CatBoostClassifier(\n    task_type='GPU', \n    devices='0',\n    iterations=200, \n    eval_metric='AUC',\n    # class_weights={0:1, 1:100},\n)\n\ncbc.fit(X_train, y_train, \n        eval_set=(X_test, y_test),\n          # plot=True, \n        # class_weights={0:1, 1:100},\n        verbose=True, \n          # cat_features=cat_features_names\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cbc.save_model('catboost_submission')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = cbc.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_score=preds, y_true=y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/test-recsys/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_user_ids = submission['Id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_users = total_df[total_df.user_id.isin(submission_user_ids)]\nsubmission_users = submission_users.to_pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_groupby = submission_users.groupby('user_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_groupby.apply(extract_features_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gb = submission_df.iloc[:100_0000].to_pandas()\n# gb = gb.groupby('user_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n# features = gb.apply(extract_features_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # total_df\n# submission_df = total_df[total_df.user_id.isin(user_ids)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x,y = concat_users_features_item_features(features[0], targets[0], all_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def concat_users_features_item_features_submission(feats, all_targets, model, topk=50):\n#     x = []\n#     y = []\n#     for cur_target in all_targets:          \n#         _x = np.hstack((\n#             feats, cur_target\n#         ))\n        \n        \n#         assert _x.shape[0] == 13        \n\n        \n#         x.append(_x)\n        \n#     features = np.vstack(x)    \n#     preds = model.predict_proba(features)[:,1]\n#     idx = preds.argsort()[::-1][:50]    \n#     return all_targets[idx]\n\n# preds = concat_users_features_item_features_submission(features.values[0], np.array(all_targets.tolist()),\n#                                                               cbc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_features = concat_users_features_item_features_submission(features.iloc[0], all_targets)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}